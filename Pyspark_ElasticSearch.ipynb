{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6s8S4rf2kmzfeH7+NSDLU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Homura-san/pyspark/blob/main/Pyspark_ElasticSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalando o Pyspark**"
      ],
      "metadata": {
        "id": "W609kqpffqqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Fm2F4FWfpJ2"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo download\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Descompactando os arquivos\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "xkPs1bU-gDgy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Definindo a variável de ambiente do Java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# Definindo a variável de ambiente do Spark\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "eaJDFl6GgFu4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instalando a findspark\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "EgRf5biogL-Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a findspark\n",
        "import findspark\n",
        "\n",
        "# Iniciando o findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "5hUzfsJrgMjg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importando o pacote necessário para iniciar uma seção Spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# iniciando o spark context\n",
        "sc = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "\n",
        "# Verificando se a sessão foi criada\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "eqeUvmBTgVGA",
        "outputId": "f6a7031d-6ee5-4427-e6a4-4f09e61d9e51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5010e155a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6068509ea69f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalando o ElasticSearch**"
      ],
      "metadata": {
        "id": "riLv4U9wWY6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io\n",
        "!pip install elasticsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBXSP181WmG3",
        "outputId": "9dfa745a-7eba-43ed-b4ef-73bbf5faaefa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.32.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.32.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.7.0-py3-none-any.whl (387 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.9/387.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elastic-transport<9,>=8\n",
            "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.15)\n",
            "Installing collected packages: elastic-transport, elasticsearch\n",
            "Successfully installed elastic-transport-8.4.0 elasticsearch-8.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from elasticsearch import Elasticsearch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import tensorflow_io as tfio"
      ],
      "metadata": {
        "id": "nflxmJQjWpW4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validando imports do tf e tfio"
      ],
      "metadata": {
        "id": "NVGfbrA4W0Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tensorflow-io version: {}\".format(tfio.__version__))\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htwzRh4yW7NG",
        "outputId": "9b76b120-ceae-438e-e846-550ed50f3da7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow-io version: 0.32.0\n",
            "tensorflow version: 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baixando e instalando a instância do Elasticsearch"
      ],
      "metadata": {
        "id": "sWC5eySaXTvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512\n",
        "tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "sudo chown -R daemon:daemon elasticsearch-7.9.2/\n",
        "shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmWuRpchXaUh",
        "outputId": "988516bc-85a0-43e4-d69e-6e26e980b081"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elasticsearch-oss-7.9.2-linux-x86_64.tar.gz: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "metadata": {
        "id": "Yhv_akR_Xp29"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sleep for few seconds to let the instance start.\n",
        "time.sleep(20)"
      ],
      "metadata": {
        "id": "ewPObPDLXvA1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "ps -ef | grep elasticsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHoM9NUUXxTt",
        "outputId": "1e2a5a23-54f4-47f0-bad7-911a92838b6a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        4083    4081  0 20:50 ?        00:00:00 sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch\n",
            "daemon      4084    4083 57 20:50 ?        00:00:20 /content/elasticsearch-7.9.2/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-4283411181427021249 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/content/elasticsearch-7.9.2 -Des.path.conf=/content/elasticsearch-7.9.2/config -Des.distribution.flavor=oss -Des.distribution.type=tar -Des.bundled_jdk=true -cp /content/elasticsearch-7.9.2/lib/* org.elasticsearch.bootstrap.Elasticsearch\n",
            "root        4448    4446  0 20:51 ?        00:00:00 grep elasticsearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "curl -sX GET \"localhost:9200/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9iU_EWKXzRN",
        "outputId": "4a9a92b6-3bae-4607-d889-1bc0c3641ce7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"6068509ea69f\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"vdS6XdZeRLaxOzXGKFm2PA\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"oss\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importando Arquivo para teste**"
      ],
      "metadata": {
        "id": "EBjNIhJqgafv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo download do arquivo\n",
        "!wget --verbose --show-progress --no-check-certificate https://raw.githubusercontent.com/jonates/opendata/master/receita_federal/receita_federal_arrecadacao_por_UF_2020.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQOlMyD0ggG3",
        "outputId": "8ba86d36-a081-4636-cfa2-bbc98c1f397d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 13:46:38--  https://raw.githubusercontent.com/jonates/opendata/master/receita_federal/receita_federal_arrecadacao_por_UF_2020.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6216 (6.1K) [text/plain]\n",
            "Saving to: ‘receita_federal_arrecadacao_por_UF_2020.csv’\n",
            "\n",
            "\r          receita_f   0%[                    ]       0  --.-KB/s               \rreceita_federal_arr 100%[===================>]   6.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-04 13:46:38 (54.8 MB/s) - ‘receita_federal_arrecadacao_por_UF_2020.csv’ saved [6216/6216]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# carregando um conjunto de dados que baixamos da internet\n",
        "receitafederal = sc.read.csv(\n",
        "    path = \"/content/receita_federal_arrecadacao_por_UF_2020.csv\", \n",
        "    inferSchema = True, \n",
        "    header = True,\n",
        "    sep = ';', \n",
        "    encoding = \"UTF-8\")"
      ],
      "metadata": {
        "id": "fdvC1UJpgjUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o tipo de objeto criado\n",
        "type(receitafederal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7j_oAWcgoIY",
        "outputId": "30e72d00-173f-42e4-8011-4ccca6258463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Espiando o dataset\n",
        "receitafederal.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "BKz3Ftpsgq2_",
        "outputId": "50dbad71-5064-4314-d50f-2616d25871fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-84940c8242a9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Espiando o dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreceitafederal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'receitafederal' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o schema() deste sparkdataframe\n",
        "receitafederal.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NULRlwfgtV_",
        "outputId": "1e6823a5-287d-470a-9f7f-de0cf9cb8015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- uf: string (nullable = true)\n",
            " |-- regiao: string (nullable = true)\n",
            " |-- ano: integer (nullable = true)\n",
            " |-- imposto_sobre_importacao: string (nullable = true)\n",
            " |-- imposto_sobre_exportacao: string (nullable = true)\n",
            " |-- ipi_total: string (nullable = true)\n",
            " |-- imposto_sobre_a_renda_total: string (nullable = true)\n",
            " |-- irpf: string (nullable = true)\n",
            " |-- irpj: string (nullable = true)\n",
            " |-- imposto_s_renda_retido_na_fonte: string (nullable = true)\n",
            " |-- imposto_s_operacoes_financeiras: string (nullable = true)\n",
            " |-- imposto_territorial_rural: string (nullable = true)\n",
            " |-- cofins: string (nullable = true)\n",
            " |-- contribuicao_para_o_pis_pasep: string (nullable = true)\n",
            " |-- csll: string (nullable = true)\n",
            " |-- cide_combustiveis: string (nullable = true)\n",
            " |-- cpsss_contrib_p_o_plano_de_segurid_social_serv_publico: string (nullable = true)\n",
            " |-- outras_receitas_administradas: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importando os métodos com funções para transformações de variáveis\n",
        "from pyspark.sql.functions import *\n"
      ],
      "metadata": {
        "id": "682QSnBbhaI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando o atributo irpf em numerica\n",
        "receitafederal = receitafederal.withColumn(\n",
        "    colName = 'irpf', \n",
        "    col = regexp_replace('irpf',',','.').cast('float')\n",
        "    )\n",
        "\n",
        "# Inspecionando o resultado\n",
        "receitafederal.select('irpf').printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_23xaH1Ghd-W",
        "outputId": "295ee54a-fcf4-4afa-a582-243e3c8dcabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- irpf: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o total do irpf por Região do Brasil\n",
        "receitafederal.groupBy('regiao').sum('irpf').orderBy('regiao').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqwyQx2jhg5t",
        "outputId": "77fbfbd5-1075-469c-9276-70bb92da145c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------+\n",
            "|      regiao|     sum(irpf)|\n",
            "+------------+--------------+\n",
            "|Centro-Oeste| 3.354157696E9|\n",
            "|    Nordeste| 4.303029696E9|\n",
            "|       Norte| 1.404179308E9|\n",
            "|     Sudeste|2.496098528E10|\n",
            "|         Sul| 7.380957184E9|\n",
            "|       Total|4.140331008E10|\n",
            "+------------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}